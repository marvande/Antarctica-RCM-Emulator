{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b0f295d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setGPU: Setting GPU to: 0\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "import torch\n",
    "import keras\n",
    "import tensorflow as tf \n",
    "import setGPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66185ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting setGPU\n",
      "  Using cached setGPU-0.0.7.tar.gz (1.1 kB)\n",
      "Collecting gpustat\n",
      "  Using cached gpustat-0.6.0.tar.gz (78 kB)\n",
      "Requirement already satisfied: six>=1.7 in /home/marvande/.conda/envs/py39/lib/python3.9/site-packages (from gpustat->setGPU) (1.16.0)\n",
      "Collecting nvidia-ml-py3>=7.352.0\n",
      "  Using cached nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
      "Collecting psutil\n",
      "  Downloading psutil-5.9.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
      "\u001b[K     |████████████████████████████████| 280 kB 6.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting blessings>=1.6\n",
      "  Using cached blessings-1.7-py3-none-any.whl (18 kB)\n",
      "Building wheels for collected packages: setGPU, gpustat, nvidia-ml-py3\n",
      "  Building wheel for setGPU (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for setGPU: filename=setGPU-0.0.7-py3-none-any.whl size=1532 sha256=3945bfec402e9c7458429f9e3e8b8263ca9353b341363e9e57ebf021c7a2711d\n",
      "  Stored in directory: /home/marvande/.cache/pip/wheels/d1/28/5a/15829f92778b3d70aa1476d73e84ce583bf7aac74aea27c502\n",
      "  Building wheel for gpustat (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gpustat: filename=gpustat-0.6.0-py3-none-any.whl size=12617 sha256=50d06529324bcefae383d8d06ae225e24de2b3582067d775a6d3e5989130cdd4\n",
      "  Stored in directory: /home/marvande/.cache/pip/wheels/85/da/41/d4911a70476938af98e21815fb08e27b97c6729c56db1587dc\n",
      "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19190 sha256=403ef288d4e642972a1c4bd0ebb9bf5f08e760fa5933d822f5ba10750c512ab1\n",
      "  Stored in directory: /home/marvande/.cache/pip/wheels/f6/d8/b0/15cfd7805d39250ac29318105f09b1750683387630d68423e1\n",
      "Successfully built setGPU gpustat nvidia-ml-py3\n",
      "Installing collected packages: psutil, nvidia-ml-py3, blessings, gpustat, setGPU\n",
      "Successfully installed blessings-1.7 gpustat-0.6.0 nvidia-ml-py3-7.352.0 psutil-5.9.0 setGPU-0.0.7\n"
     ]
    }
   ],
   "source": [
    "! pip install setGPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4a3fa4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4452710000808708169\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 14:08:29.295646: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54c6008a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized device: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m physical_devices \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mlist_physical_devices(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCPU\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_memory_growth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphysical_devices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/framework/config.py:594\u001b[0m, in \u001b[0;36mset_memory_growth\u001b[0;34m(device, enable)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.experimental.set_memory_growth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_memory_growth\u001b[39m(device, enable):\n\u001b[1;32m    571\u001b[0m   \u001b[38;5;124;03m\"\"\"Set if memory growth should be enabled for a `PhysicalDevice`.\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \n\u001b[1;32m    573\u001b[0m \u001b[38;5;124;03m  If memory growth is enabled for a `PhysicalDevice`, the runtime initialization\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;124;03m    RuntimeError: Runtime is already initialized.\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 594\u001b[0m   \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_memory_growth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1435\u001b[0m, in \u001b[0;36mContext.set_memory_growth\u001b[0;34m(self, dev, enable)\u001b[0m\n\u001b[1;32m   1432\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_physical_devices()\n\u001b[1;32m   1434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dev \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_physical_devices:\n\u001b[0;32m-> 1435\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized device: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mrepr\u001b[39m(dev))\n\u001b[1;32m   1437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dev \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_virtual_device_map:\n\u001b[1;32m   1438\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1439\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set memory growth on device when virtual devices configured\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized device: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('CPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb7aab28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 14:27:48.685728: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "if len(tf.config.list_physical_devices('GPU'))>0:\n",
    "    physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34595801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14897380349483319384\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b774ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA supported by this system? True\n",
      "CUDA version: 11.3\n",
      "ID of current CUDA device:0\n",
      "Name of current CUDA device:Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "  \n",
    "# Storing ID of current CUDA device\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device:{torch.cuda.current_device()}\")\n",
    "        \n",
    "print(f\"Name of current CUDA device:{torch.cuda.get_device_name(cuda_id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c8a266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
