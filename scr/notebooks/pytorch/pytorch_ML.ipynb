{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "nervous-explosion",
   "metadata": {},
   "source": [
    "# Code in pytorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.path as mpath\n",
    "import os\n",
    "import sys\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "from re import search\n",
    "from math import cos,sin,pi\n",
    "import random as rn\n",
    "\n",
    "# xarray and cartopy plots\n",
    "import xarray as xr\n",
    "#import cf_units\n",
    "\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import pyproj\n",
    "from pyproj import Transformer\n",
    "#import rasterio\n",
    "\n",
    "# Google file system\n",
    "#import gcsfs\n",
    "#from google.cloud import storage\n",
    "\n",
    "# ML\n",
    "from scipy import ndimage\n",
    "import torch\n",
    "import tensorflow as tf \n",
    "\n",
    "\"\"\"\n",
    "import keras\n",
    "import tensorflow as tf \n",
    "from keras import backend as K\n",
    "\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, UpSampling2D, Conv2DTranspose, Reshape, concatenate, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from netCDF4 import Dataset\"\"\"\n",
    "#from netCDF4 import Dataset\n",
    "#import h5netcdf\n",
    "#import netCDF4\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import setGPU\n",
    "\n",
    "# Import custom scripts\n",
    "sys.path.append('../')\n",
    "#from process_pangeo import *\n",
    "#from GC_scripts import *\n",
    "#from processRCM import *\n",
    "#from reprojectionFunctions import *\n",
    "#from MakeInputFunctions import *\n",
    "#from model import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-allah",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "  \n",
    "# Storing ID of current CUDA device\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device:{torch.cuda.current_device()}\")\n",
    "        \n",
    "print(f\"Name of current CUDA device:{torch.cuda.get_device_name(cuda_id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-chapel",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-column",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration file:\n",
    "from config import *\n",
    "from helperFunctions import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-gentleman",
   "metadata": {},
   "source": [
    "## Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "if downloadFromGC:\n",
    "    downloadFileFromGC(pathGC, '', fileGCMLike)\n",
    "    GCMLike = xr.open_dataset(fileGCMLike)\n",
    "    os.remove(fileGCMLike)\n",
    "else:\n",
    "    GCMLike = xr.open_dataset(pathCluster+fileGCMLike)\n",
    "print(GCMLike.dims)\n",
    "GCMLike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-colon",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = plt.subplot(2, 1, 1, projection=ccrs.SouthPolarStereo())\n",
    "GCMLike.SMB.isel(time=0).plot(\n",
    "    x=\"x\", ax=ax, transform=ccrs.SouthPolarStereo(), add_colorbar=False\n",
    ")\n",
    "\n",
    "ax.coastlines(\"10m\", color=\"black\")\n",
    "ax.gridlines(draw_labels=True)\n",
    "\n",
    "\n",
    "ax = plt.subplot(2, 1, 2, projection=ccrs.PlateCarree())\n",
    "GCMLike.SMB.isel(time=0).plot(\n",
    "    x=\"x\", ax=ax, transform=ccrs.SouthPolarStereo(), add_colorbar=False\n",
    ")\n",
    "ax.coastlines(\"10m\", color=\"black\")\n",
    "ax.gridlines(draw_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4dbaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if downloadFromGC:\n",
    "    downloadFileFromGC(pathGC, '', fileTarget)\n",
    "    target_dataset = xr.open_dataset(fileTarget)\n",
    "    os.remove(fileTarget)\n",
    "else:\n",
    "    target_dataset = xr.open_dataset(pathCluster+fileTarget)\n",
    "print(target_dataset.dims)\n",
    "\n",
    "# Cut a small part of on the right that is not too important\n",
    "N = 160\n",
    "max_x = (N / 2) * 35 * 1000\n",
    "max_y = (N / 2) * 35 * 1000\n",
    "\n",
    "target_dataset = cutBoundaries(target_dataset, max_x, max_y)\n",
    "print(\"New target dimensions:\", target_dataset.dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6866221",
   "metadata": {},
   "source": [
    "## Create input and target:\n",
    "\n",
    "**Z**:\n",
    "- (ignore for now) External forcing also given to RCM â†’ total concentration of greenhouse gases and solar and ozone forcings\n",
    "- Cosinus, sinus vector to encode information about day of year\n",
    "- Daily spatial means and standard deviations time series for each $X_{i,j,m}$ (because normalising 2D variables removes temporal information)\n",
    "\n",
    "**X**: \n",
    "SHAPE `[nbmonths, x, y, nb_vars]`\n",
    "\n",
    "For pytorch need to put into `[nbmonths, nb_vars, x, y]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80a87f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_maker(\n",
    "    GCMLike,\n",
    "    size_input_domain=16,  # size of domain, format: 8,16,32, must be defined in advance\n",
    "    stand=True,  # standardization\n",
    "    seas=True,  # put a cos, sin vector to control the season, format : bool\n",
    "    means=True,  # add the mean of the variables raw or stdz, format : bool\n",
    "    stds=True,  # add the std of the variables raw or stdz, format : bool\n",
    "    resize_input=True,  # resize input to size_input_domain\n",
    "    region=\"Larsen\",  # region of interest\n",
    "    print_=True\n",
    "):\n",
    "\n",
    "    if region != \"whole antarctica\":\n",
    "        DATASET = createLowerInput(GCMLike, region = region, Nx=48, Ny=25, print_=False)\n",
    "    else:\n",
    "        DATASET = GCMLike\n",
    "    \"\"\"\n",
    "    MAKE THE 2D INPUT ARRAY\n",
    "    SHAPE [nbmonths, x, y, nb_vars]\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove target variable from DATASET:\n",
    "    DATASET = DATASET.drop([\"SMB\"])\n",
    "\n",
    "    nbmonths = DATASET.dims[\"time\"]\n",
    "    x = DATASET.dims[\"x\"]\n",
    "    y = DATASET.dims[\"y\"]\n",
    "    nb_vars = len(list(DATASET.data_vars))\n",
    "    VAR_LIST = list(DATASET.data_vars)\n",
    "\n",
    "    INPUT_2D_bf = np.transpose(\n",
    "        np.asarray([DATASET[i].values for i in VAR_LIST]), [1, 2, 3, 0]\n",
    "    )\n",
    "\n",
    "    # if no size is given, take smallest power of 2\n",
    "    if size_input_domain == None:\n",
    "        size_input_domain = np.max(\n",
    "            [\n",
    "                highestPowerof2(INPUT_2D_bf.shape[1]),\n",
    "                highestPowerof2(INPUT_2D_bf.shape[2]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    if resize_input:\n",
    "        # resize to size_input_domain\n",
    "        INPUT_2D = resize(INPUT_2D_bf, size_input_domain, size_input_domain, print_)\n",
    "    else:\n",
    "        INPUT_2D = INPUT_2D_bf\n",
    "\n",
    "    if stand:\n",
    "        # Standardize:\n",
    "        INPUT_2D_SDTZ = standardize(INPUT_2D)\n",
    "        # in their code with aerosols extra stuff but ignore\n",
    "        INPUT_2D_ARRAY = INPUT_2D_SDTZ\n",
    "    else:\n",
    "        INPUT_2D_ARRAY = INPUT_2D\n",
    "\n",
    "    if print_:\n",
    "        print(\"Parameters:\\n -------------------\")\n",
    "        print(\"Size of input domain:\", size_input_domain)\n",
    "        print(\"Region:\", region)\n",
    "        print(\"\\nCreating 2D input X:\\n -------------------\")\n",
    "        print(f\"Number of variables: {nb_vars}\")\n",
    "        print(f\"Variables: {VAR_LIST}\")\n",
    "        print(f\"INPUT_2D shape: {INPUT_2D_ARRAY.shape}\")\n",
    "        print(\"\\nCreating 1D input Z:\\n -------------------\")\n",
    "        \n",
    "    \"\"\"\n",
    "    MAKE THE 1D INPUT ARRAY\n",
    "    CONTAINS MEANS, STD SEASON IF ASKED\n",
    "    \"\"\"\n",
    "    \n",
    "    INPUT_1D = []\n",
    "    if means and stds:\n",
    "        vect_std = INPUT_2D.std(axis=(1, 2))\n",
    "        vect_means = INPUT_2D.mean(axis=(1, 2))\n",
    "        SpatialMean = vect_means.reshape(INPUT_2D.shape[0], 1, 1, INPUT_2D.shape[3])\n",
    "        SpatialSTD = vect_std.reshape(INPUT_2D.shape[0], 1, 1, INPUT_2D.shape[3])\n",
    "\n",
    "        INPUT_1D.append(SpatialMean)\n",
    "        INPUT_1D.append(SpatialSTD)\n",
    "        if print_:\n",
    "            print(f\"SpatialMean/std shape: {SpatialMean.shape}\")\n",
    "\n",
    "    if seas:\n",
    "        months = 12\n",
    "        cosvect = np.tile(\n",
    "            [cos(2 * i * pi / months) for i in range(months)],\n",
    "            int(INPUT_2D.shape[0] / months),\n",
    "        )\n",
    "        sinvect = np.tile(\n",
    "            [sin(2 * i * pi / months) for i in range(months)],\n",
    "            int(INPUT_2D.shape[0] / months),\n",
    "        )\n",
    "        cosvect = cosvect.reshape(INPUT_2D.shape[0], 1, 1, 1)\n",
    "        sinvect = sinvect.reshape(INPUT_2D.shape[0], 1, 1, 1)\n",
    "\n",
    "        INPUT_1D.append(cosvect)\n",
    "        INPUT_1D.append(sinvect)\n",
    "        if print_:\n",
    "            print(f\"Cos/sin encoding shape: {cosvect.shape}\")\n",
    "\n",
    "    INPUT_1D_ARRAY = np.concatenate(INPUT_1D, axis=3)\n",
    "    if print_:\n",
    "        print(f\"INPUT_1D shape: {INPUT_1D_ARRAY.shape}\")\n",
    "        \n",
    "    DATASET.close()\n",
    "    return INPUT_2D_ARRAY, INPUT_1D_ARRAY, VAR_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db745d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download GMC like RCM input data:\n",
    "downloadFromGC = False\n",
    "fileGCMLike = \"MAR(ACCESS1-3)-stereographic_monthly_GCM_like.nc\"\n",
    "if downloadFromGC:\n",
    "    downloadFileFromGC(pathGC, \"\", fileGCMLike)\n",
    "    GCMLike = xr.open_dataset(fileGCMLike)\n",
    "    os.remove(fileGCMLike)\n",
    "else:\n",
    "    GCMLike = xr.open_dataset(pathCluster+fileGCMLike)\n",
    "\n",
    "region = \"Larsen\"\n",
    "size_input_domain = 32\n",
    "\n",
    "# Make input\n",
    "i2D, i1D, VAR_LIST = input_maker(\n",
    "    GCMLike,\n",
    "    size_input_domain,\n",
    "    stand=True,  # standardization\n",
    "    seas=True,  # put a cos,sin vector to control the season, format : bool\n",
    "    means=True,  # add the mean of the variables raw or stdz, format : r,s,n\n",
    "    stds=True,\n",
    "    resize_input=True,\n",
    "    region=region,\n",
    ")\n",
    "\n",
    "inputs_2D = []\n",
    "inputs_1D = []\n",
    "inputs_1D.append(i1D)\n",
    "inputs_2D.append(i2D)\n",
    "\n",
    "# Make a non standardised version for plots:\n",
    "i2D_ns, i1D_ns, var_list = input_maker(\n",
    "    GCMLike,\n",
    "    size_input_domain,\n",
    "    stand=False,  # standardization\n",
    "    seas=True,  # put a cos,sin vector to control the season, format : bool\n",
    "    means=True,  # add the mean of the variables raw or stdz, format : r,s,n\n",
    "    stds=True,\n",
    "    resize_input=False,\n",
    "    region=region,\n",
    "    print_=False,\n",
    ")\n",
    "\n",
    "inputs_2D_ns = []\n",
    "inputs_1D_ns = []\n",
    "inputs_1D_ns.append(i1D_ns)\n",
    "inputs_2D_ns.append(i2D_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7028701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_maker(\n",
    "    target_dataset, \n",
    "    region=\"Larsen\", # region of interest\n",
    "    resize=True, # resize to target_size\n",
    "    target_size=None # if none provided and resize true, set to min highest power of 2\n",
    "):\n",
    "    target_times = []\n",
    "    targets = []\n",
    "\n",
    "    if region != \"Whole antarctica\":\n",
    "        lowerTarget = createLowerTarget(target_dataset, region = region, Nx=64, Ny=64, print_=False)\n",
    "        targetArray = lowerTarget.SMB.values\n",
    "    else:\n",
    "        targetArray = target_dataset.SMB.values\n",
    "\n",
    "    targetArray = targetArray.reshape(\n",
    "        targetArray.shape[0], targetArray.shape[1], targetArray.shape[2], 1\n",
    "    )\n",
    "\n",
    "    if target_size == None:\n",
    "        # resize to highest power of 2:\n",
    "        target_size = np.min(\n",
    "            [\n",
    "                highestPowerof2(targetArray.shape[1]),\n",
    "                highestPowerof2(targetArray.shape[2]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    if resize:\n",
    "        target_SMB = resize(targetArray, target_size, target_size)\n",
    "    else:\n",
    "        target_SMB = targetArray\n",
    "\n",
    "    targets.append(target_SMB)\n",
    "    target_times.append(target_dataset.time.values)\n",
    "\n",
    "    full_target = np.concatenate(targets, axis=0)\n",
    "\n",
    "    return full_target, target_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f1623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_target, target_times = target_maker(\n",
    "    target_dataset, region=\"Larsen\", resize=False\n",
    ")\n",
    "# Full target to model\n",
    "target_time = np.concatenate(target_times, axis=0)\n",
    "target_lon = target_dataset[\"x\"]\n",
    "target_lat = target_dataset[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e17af91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full input to model\n",
    "full_input=[np.concatenate(inputs_2D,axis=0),np.concatenate(inputs_1D,axis=0)]\n",
    "full_input_ns=[np.concatenate(inputs_2D_ns,axis=0),np.concatenate(inputs_1D_ns,axis=0)]\n",
    "\n",
    "print(\"Shapes of targets and inputs:\\n---------------------------\")\n",
    "print(\"Target:\", full_target.shape)\n",
    "print(\"Input 2D:\", full_input[0].shape)\n",
    "print(\"Input 1D:\", full_input[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420cda85",
   "metadata": {},
   "source": [
    "### Change to tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f580aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38402bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(full_input[0].transpose(0, 3,1,2))\n",
    "Z = torch.tensor(full_input[1].transpose(0, 3,1,2))\n",
    "Y = torch.tensor(full_target.transpose(0, 3,1,2))\n",
    "X.shape, Z.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39615a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "\n",
    "dataset = TensorDataset(X, Z, Y)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Example:\n",
    "(x, z, y) = next(iter(loader))\n",
    "print(x.shape, z.shape, y.shape)\n",
    "    \n",
    "# 2. Split into train / validation partitions\n",
    "val_percent = 0.2\n",
    "n_val = int(len(dataset) * val_percent)\n",
    "n_train = len(dataset) - n_val\n",
    "train_set, val_set = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba865300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create data loaders\n",
    "batch_size = 32\n",
    "loader_args = dict(batch_size=batch_size)\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_set, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "# Display image and label.\n",
    "train_X, train_Y, train_Z = next(iter(train_loader))\n",
    "print(f\"2D Feature batch shape: {train_X.size()}\")\n",
    "print(f\"1D Feature batch shape: {train_Z.size()}\")\n",
    "print(f\"Labels batch shape: {train_Y.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6bfb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2dtrain_ = train_X.cpu().detach().numpy()\n",
    "sampletarget_ = train_Y.cpu().detach().numpy()\n",
    "\n",
    "dt = pd.to_datetime([GCMLike.time.isel(time=randTime).values])\n",
    "time = str(dt.date[0])\n",
    "\n",
    "if REGION == \"Larsen\":\n",
    "        sample2dtrain_ = resize(sample2dtrain_, 25, 48, print_=False)\n",
    "else:\n",
    "        sample2dtrain_ = resize(sample2dtrain_, 25, 90, print_=False)\n",
    "\n",
    "    sampletarget_ = sampletarget_.reshape(\n",
    "        sampletarget_.shape[1], sampletarget_.shape[0], 1\n",
    "    )\n",
    "    M = 2\n",
    "    vmin = np.min(sampletarget_)\n",
    "    vmax = np.max(sampletarget_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca0b505",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot(1, 1, 1, projection=ccrs.SouthPolarStereo())\n",
    "plotTrain(GCMLike, sample2dtrain_, 4, ax, time, VAR_LIST, region='Larsen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdc5f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot(1, 1, 1, projection=ccrs.SouthPolarStereo())\n",
    "plotTarget(target_dataset, sampletarget_, ax, vmin, vmax, region='Larsen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edada3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a2b881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f8cc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Z, Y):\n",
    "        self.target = Y\n",
    "        self.X = X\n",
    "        self.Z = Z\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X2D = self.X[idx,:,:,:]\n",
    "        Z1D = self.Z[idx,:,:,:]\n",
    "        target = self.target[idx,:,:,:]\n",
    "        \n",
    "        return {\n",
    "            'X': X2D,\n",
    "            'Z': Z1D,\n",
    "            'target': target\n",
    "        }\n",
    "    \n",
    "dataset = CustomDataset(X,Z,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eaf08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create data loaders\n",
    "batch_size = 32\n",
    "loader_args = dict(batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n",
    "val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e419a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image and label.\n",
    "train_X, train_Z, train_Y = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_X.size()}\")\n",
    "print(f\"Labels batch shape: {train_Z.size()}\")\n",
    "print(f\"Labels batch shape: {train_Y.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f935d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a677c99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "275.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
