%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% EPFL report package, main thesis file
% Goal: provide formatting for theses and project reports
% Author: Mathias Payer <mathias.payer@epfl.ch>
%
% This work may be distributed and/or modified under the
% conditions of the LaTeX Project Public License, either version 1.3
% of this license or (at your option) any later version.
% The latest version of this license is in
%   http://www.latex-project.org/lppl.txt
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[a4paper,11pt,oneside]{report}
% Options: MScThesis, BScThesis, MScProject, BScProject
\usepackage[MScThesis,lablogo]{EPFLreport}
\usepackage{datetime}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xspace}
\usepackage{array}
\usepackage{lscape}
\usepackage{booktabs}
\usepackage{subcaption}
\usepackage{gensymb}
\usepackage{stmaryrd}
\usepackage{verbatim}
\usepackage{siunitx}


\usepackage{hyperref}
\usepackage{graphicx}

\title{Regional Climate Model Emulator based on Deep Learning: future SMB predictions over Antarctica}
\author{Marijn van der Meer}
\supervisor{Sophie de Roda Husman}
\adviser{Prof. Dr. sc. EPFL Martin Jäggi}
\expert{Prof. Dr. sc. TU Delft Stef Lhermitte}

\newcommand{\sysname}{FooSystem\xspace}

\begin{document}
\maketitle
\makededication
\makeacks

\begin{abstract}
The \sysname tool enables lateral decomposition of a multi-dimensional
flux compensator along the timing and space axes.

The abstract serves as an executive summary of your project.
Your abstract should cover at least the following topics, 1-2 sentences for
each: what area you are in, the problem you focus on, why existing work is
insufficient, what the high-level intuition of your work is, maybe a neat
design or implementation decision, and key results of your evaluation.
\end{abstract}

\begin{frenchabstract}
For a doctoral thesis, you have to provide a French translation of the
English abstract. For other projects this is optional.
\end{frenchabstract}

\maketoc

%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}
%%%%%%%%%%%%%%%%%%%%%%

\begin{itemize}
    \item Traditional U-Net is a fully convolutional CNN architecture specifically developed for biomedical image segmentation~\cite{Ronneberger2015}.  
        \item U-Net shows high performance in classification and segmentation tasks where the network is trained to predict a class for each pixel. But U-Nets are also used for image processing tasks, such as super resolution. They have been found to be particularly effective in cases where the output and inputs are of similar size. In our case, we applied it to a time series prediction task in which the network has to predict an exact value for each pixel.
    \item using attention in a CNN facilitates the network to focus on specific parts of the input. 
\end{itemize}



The introduction is a longer writeup that gently eases the reader into your
thesis~\cite{dinesh20oakland}. Use the first paragraph to discuss the setting.
In the second paragraph you can introduce the main challenge that you see.
The third paragraph lists why related work is insufficient.
The fourth and fifth paragraphs discuss your approach and why it is needed.
The sixth paragraph will introduce your thesis statement. Think how you can
distill the essence of your thesis into a single sentence.
The seventh paragraph will highlight some of your results
The eights paragraph discusses your core contribution.

This section is usually 3-5 pages.

Surface mass balance (SMB) provides mass input to the surface of the Antarctic and Greenland Ice Sheets and therefore comprises an important control on ice sheet mass balance and resulting contribution to global sea level change. As ice sheet SMB varies highly across multiple scales of space (meters to hundreds of kilometers) and time (hourly to decadal), it is notoriously challenging to observe and represent in models. In addition, SMB consists of multiple components, all of which depend on complex interactions between the atmosphere and the snow/ice surface, large-scale atmospheric circulation and ocean conditions, and ice sheet topography.~\cite{Lenaerts}

%%%%%%%%%%%%%%%%%%%%
\chapter{State of the art}
%%%%%%%%%%%%%%%%%%%%

The related work section covers closely related work. Here you can highlight
the related work, how it solved the problem, and why it solved a different
problem. Do not play down the importance of related work, all of these
systems have been published and evaluated! Say what is different and how
you overcome some of the weaknesses of related work by discussing the 
trade-offs. Stay positive!

This section is usually 3-5 pages.

\section{Regional Climate Model Emulator based on Deep Learning: Concept and First Evaluation of a Novel Hybrid Downscaling Approach \cite{Doury}}
This paper proposes a novel hybrid downscaling approach that emulates the downscaling function of a a regional climate model.

\begin{itemize}
\item RCM: EURO-CORDEX simulations based on the CNRM-ALADIN63, 1951-2100 RCP4.5 and RCP8.5
\item GCM: CNRM-CM5 used in CMIP5 → 6h frequency + sea surface temperature, sea ice cover and aerosol optical depth at monthly frequency
\item ML model learns the RCM transformation of the large-scale climate information into local-scale
\item Target variable: near surface temperature (TAS)
\item Target domain: southwest European domain
\item Historical period: 1951 to 2005
\item Scenarios (2006-2100): based on two Representative Concentration Pathways from CMIP5; RCP4.5 and RCP8.5
\end{itemize}
Computational performance:
\begin{itemize}
    \item U-Net: fully convolutional neural network algorithm
    \item Substantial computational gain regarding RCM computational cost
    \begin{itemize}
        \item 2h training on GPU + downscaling instantaneous
        \item RCM simulation involves weeks of computation on super-computer
    \end{itemize}
\end{itemize}
Training of model 
\begin{itemize}
    \item RCM can be broken down into a large scale transformation and a downscaling function
    \item Training using existing RCM simulations → learn large scale/local scale relationship in different climates and in future climate
    \item Training in perfect model framework: input and output to ML model come from same RCM simulation → focus on downscaling function
    \item Input variable: daily large-scale and low-resolution RCM information (upsampled to GCM like resolution)
    \item Output variable: daily maps of TAS at RCM resolution (~12 \si{mmWe/day}\sci{km})
    \item Emulator is RCM-dependent as downscaling function depends on RCM choice
\end{itemize}
Results
\begin{itemize}
    \item Emulator evaluated in both perfect model (evaluation 1) and GCM worlds (evaluation 2)
    \item capture very well transformation from low resolution information to high resolution TAS
    \item robust to different sources of input
    \item succeeds very well in reproducing high resolution spatial structure and daily variability of the RCM
    \item evaluation 1 shows that emulator is able to reproduce original series almost perfectly
    \item training emulator in future climate improves its ability to reproduce warmer climate
    \item limitations in accurately simulating extreme events and complete climate change magnitude
    \item RCM-GCM large scales inconsistencies when evaluating on GCM. Does not learn to reproduce large scale transformations (because trained only on RCM)
\end{itemize}
\section{Diverging future surface mass balance between the Antarctic ice shelves and grounded ice sheet \cite{Kittel}}

\section{SmaAt-UNet: Precipitation Nowcasting using a Small Attention-UNet Architecture~\cite{smatunet}}


%%%%%%%%%%%%%%%%
\chapter{Model and methods}
%%%%%%%%%%%%%%%%

\input{tables/notations}

\begin{itemize}
\item \textbf{Global idea}: the RCM-emulator $\hat{F}$ uses a neural network architecture to estimate the downscaling function $F$ in 
\begin{equation}\label{eq:emulator-equation}
    Y = \operatorname{F}(X) \;\;\;\; X\subset\mathcal{D}, Y\subset\mathcal{E}
    \end{equation}
where $X$ are low-resolution variables from a global climate simulation over an input domain $\mathcal{D}$ and $Y$ is a high-resolution surface variable inside a regional climate model over a target domain $\mathcal{E}$. 
\item Flow of model and methods section: 
\begin{itemize}
    \item Data: climate models used -> target and input domains -> variables chosen (input features)
    \item Model: architecture -> perfect model framework (creation of UPRCM) -> training flow (on GCM and UPRCM) -> evaluation flow
\end{itemize}
\end{itemize}

\section{Data}\label{sec:data}
\subsection{Climate model}
\begin{itemize}
   \item RCM: RCM variable emulated by $\hat{F}$ is the monthly surface mass balance (SMB) values from MAR(ACCESS1.3), a regional downscaling of the global climate model ACCESS 1.3 (CMIP5~\cite{ACCESS13, CMIP5}) by the Modèle Atmosphérique Régional (MAR). 
    \item MAR is known for accurately modeling physical processes in polar regions such as surface mass balance, air-snow interactions, and atmospheric circulation over ice sheets~\cite{MAR}. 
    \item Why: According to the comparison of climate model studies conducted in~\cite{Kittel, Agosta2015}, ACCESS 1.3 and MAR(ACCESS 1.3) were the models that most accurately represented the present Antarctic climate in comparison to ERA-Interim. For this reason, we chose MAR(ACCESS 1.3) and its corresponding global climate model as climate simulations for our Emulator.  
    \item Time-frame: historical values from 1980-2006 and future climate simulation RCP 8.5~\cite{Moss2010} from 2006-2100. 
    \item Grid and resolution: RCM grid in south polar stereographic coordinates of $35 \times 35$ \si{mmWe/day}\sci{km} resolution. GCM resolution of 1.25° latitude by 1.875° longitude (approximately $68 \times 206$ \si{mmWe/day}\sci{km}), using a staggered Arakawa C grid~\cite{ACCESS13, ACCESS13_2}. 
    \item Reprojection: to have both regional and global climate models in the same projection system, we project the GCM to polar stereographic coordinates (see Annex for details [REF ANNEX]). 
\end{itemize}

\begin{figure}[!t]
  \centering
  \includegraphics[width=\columnwidth]{images/domains.pdf}
  \caption []{\small Mean surface mass balance over Antarctica (left) and Antarctic Peninsula (right) from 1990-2100. Regions chosen as target domain $\mathcal{E}$ (in red) and input domain $\mathcal{D}$ (in blue) for Emulator.}
  \vspace{-3mm}
    \label{fig:region-of-choice}
\end{figure}


\subsection{Target and input domain}
\begin{itemize}
   \item Target domain: The target domain used for this model is a grid box of $64 \times 64$ at 35 \si{mmWe/day}\sci{km} resolution that contains the Antarctic Peninsula in West Antarctica. 
    \item Antarctic peninsula: 
    \begin{itemize}
        \item The Antarctic Peninsula is the most northerly part of Antarctica
        \item It covers approximately 5 million square kilometers and is mainly covered by ice. Major ice shelves include the Larsen and Ronne ice shelves.
        \item It is very mountainous, with its highest peaks rising to about 3'000 m
        \item Temperature: it has the mildest climates on this continent. Its temperatures are warmest in January, averaging 1 to 2 $\degree C$, and coldest in June, averaging from -15 to -20 $\degree C$~\cite{AntarcticPeninsula}
        \item Precipitation: varies greatly within the Antarctic Peninsula. The peninsula's tip has the highest precipitation levels, with 35–50 cm per year. On the west coast and northeast coast, occasional rain leaves precipitation at 35 cm. Along the east coast and the interior of Antarctica, the climate is drier, with precipitation that ranges from 10-15 cm~\cite{antarctic-climate, antarctic-climate-2}
    \end{itemize} 
    \item Why this region: 
    \begin{itemize}
        \item Because of the specific patterns of climate variables such as temperature and precipitation, the Antarctic Peninsula has a high annual and geographical variability in SMB values. 
        \item This shows when looking at mean SMB values as in Fig.~\ref{fig:region-of-choice}. The peninsula's tip and west coast offer higher values than the rest. Mean SMB values range from -9.2 to 9.9 \si{mmWe/day} and the extremes observed in this region over the whole time frame of 1980-2100 are a minimum of -59.0 \si{mmWe/day} and a maximum of 30.2 \si{mmWe/day}. 
        \item All of this makes this region very interesting to us because we want to see how the Emulator adapts to different annual patterns of SMB over our target domain.  
    \end{itemize}
    \item Input domain: $48\times25$ grid box (Fig.~\ref{fig:region-of-choice}) defined around the target domain that is resized to $32\times 32$ by bilinear interpolation so as to give the model a square input.
\end{itemize}


\subsection{Features}\label{subsec:features}
\begin{itemize}
    \item The Emulator receives as input features $(X, Z)$ that consist of two-dimensional variable $X$, and one-dimensional $Z$ (Table~\ref{tab:features}). 
    \item X: The two-dimensional feature $X$ contains eight different atmospheric variables measured daily at (near) surface level. After a monthly mean aggregation, the frequency of variables is monthly.
    \item Normalisation of X: These variables are normalised according to their spatial mean $\bar{X}_{t,x}$ and standard deviation $\sigma(X_{t,x})$ for eac time-step $t\in T$:
    
    \begin{equation}\label{eq:normalisation-X}
    \tilde{X}_{t,i,j,x} = \frac{X_{t,i,j,x}-\bar{X}_{t,x}}{\sigma(X_{t,x})} \;\;\;\; t\in T, \forall (i,j) \in \mathcal{D}, x\in C_1
\end{equation}
    \item Feature selection: In terms of feature selection, we decided to follow the same procedure as in~\cite{Doury} and give all available variables to the Emulator and later evaluate their feature importance. 
    
\item Temporal encoding Z: \begin{itemize}
    \item 
The one-dimensional variable $Z$ includes the time-series of spatial means $\bar{X}_{t,x}$ and standard deviations $\sigma(X_{t,x})$ for each atmospheric variable $x\in C_1$.

\item It also includes a cosine, sine vector to encode the information about the month of the year.
    \begin{equation*}
       \operatorname{cos}\left(\frac{2\pi t}{12}\right);\; \operatorname{sin}\left(\frac{2\pi t}{12}\right) \;\;\;\; \forall t\in T
    \end{equation*}
    
    \item Overall this gives the following equation for $Z$:
    \begin{equation}\label{eq:Z}
    Z = \left[ \bar{X}_{t\in T, x\in C_1}, \sigma\left(X_{t\in T, x\in C_1}\right), \operatorname{cos}, \operatorname{sin} \right] \subset T \times C_2
\end{equation}
    \item Why: because the $X$ variables are normalized at each time step by their spatial mean, they do not carry any temporal encoding. Adding Z to the model allows it to have access to this information. 
    

\item Normalisation of Z: each of the spatial means $\bar{X}_{t,x}$ and standard deviations $\sigma(X_{t,x})$ in Z are normalised according to a reference period ($\mathrm{ref}=$1980-2000)~\cite{Doury}:
\begin{equation}\label{eq:normalisation-Z}
    \tilde{Z}_{t,z} = \frac{Z_{t,z}-\bar{Z}_{\mathrm{\mathrm{ref}},z}}{\sigma(Z_{\mathrm{ref},z})} \;\;\;\; t\in T, z\in C_2
\end{equation}
where $\bar{Z}_{\mathrm{ref},z}$ and $\sigma(Z_{\mathrm{ref},z})$ are respectively the temporal mean and standard deviation of the spatial means or standard deviations of $X_{\mathrm{ref}, x} \subset T_{\mathrm{ref}}\times C_1$.
\end{itemize}



\end{itemize}

\input{tables/variables_table}


\section{Model}\label{sec:model}

\begin{figure}[!t]
  \centering
  \includegraphics[width=\columnwidth]{doc/Thesis-latex/images/unet-with-data.pdf}
  \caption []{\small Illustration of an observation at time-step $t$. Left: 2D input variables $X_t$ on the input domain with its corresponding 1D variable $Z_t$. Right: target surface mass balance (SMB) $Y_t$ on the target domain. Middle: scheme of the U-Net architecture used for this paper. }
  \vspace{-3mm}
  \label{fig:example-features}
\end{figure}

\subsection{Architecture}\label{subsec:architecture}
\begin{itemize}
    \item The Emulator's architecture extends the U-Net used to emulate near-surface temperature in~\cite{Doury} with mechanisms from the SmaAt-UNet model~\cite{smatunet} (Fig.~\ref{fig:example-features}).
     \item SmaAt-UNet: SmaAt-UNet extends the traditional U-Net architecture~\cite{unet} with CBAM attention mechanism and depthwise-separable convolutions instead of regular convolutional operations. 
    \item Architecture: 
    \begin{itemize}
    \item The network is U-shaped as it is divided into a down-sampling/encoder section that forms the left side and an up-sampling/decoder on the right.
    \item Encoder: the Encoder consists of double convolution (blue arrows) followed by max-pooling (red arrows). This process halves the image size and doubles the number of channels. Instead of the traditional U-Net convolutional operations, the Emulator uses depthwise-separable convolutions (DSC), designed to reduce the number of parameters~\cite{smatunet}.
    \item Bottom of U-Net: At the bottom of the U-Net, encoded spatial information from $X_t$ and temporal information from $Z_t$ are concatenated. The corresponding 1D input $Z_t$ of $X_t$ first goes through a fully dense neural network to reach the same number of channels as the output of the last layer of the Encoder. Then, it is concatenated with the Encoder output at the bottom of the “U”. This constrains the U-Net to give equal importance to the spatial and temporal inputs before starting the decoding path and generating the high-resolution SMB image~\cite{Doury}. 
    \item Decoder: three parts; a 2D transposed convolution operation (green arrows) to double the image size, a concatenation of the resulting feature maps with the previous Encoder’s attention maps (white blocks) via skip-connections (grey arrows), and lastly a double depthwise-separable to half the number of channels (blue arrows). 
    \item Skip-connections: skip-connections between layers (grey arrows) make it possible to skip large sections if required and create a smoother loss surface. 
    \item  Last layers: up-sampling layer (light blue arrow) to reach target size ($64\times 64$) and $1\times1$ convolution (pink arrow) to change the number of channels from $64$ to $1$, and outputs a single image representing the SMB values predicted by the network at time-step $t$.
    \item Attention: Convolutional block attention modules (CBAMs, yellow arrow)~\cite{smatunet} are placed after each double convolution in the Encoder and used to detect important features over the channels and spatial regions of the inputs. In CBAMs, the attention mechanism is first applied over the channels of the image and then the spatial dimension. Note that the input to the next layer of the Encoder is not the attention feature map (white block) but the convoluted and downsampled image of the previous layer (dark blue block). This way, the original image features are preserved throughout the Encoder layers. Finally, the attention blocks are fed through skip-connections to the corresponding Decoder layer to be concatenated~\cite{smatunet}. Contrary to the DSC convolutions used in the Encoder and Decoder, CBAMs use regular convolutions.  
    \end{itemize}
    \item Code: Architecture implemented in PyTorch 1.11 and available on LINK GITHUB
\end{itemize}

\subsection{Perfect model framework}\label{subsec:perfect-model}
\begin{itemize}
    \item The authors of~\cite{Kittel} trained their Emulator in a \textit{perfect model framework} where both the low-resolution inputs and high-resolution SMB truth used in the Machine Learning model come from the same RCM simulation. 
    \item Why:
    \begin{itemize}
        \item Their Emulator aims to learn the downscaling function $F$ of the RCM in Eq.~\ref{eq:emulator-equation}.
        \item For this, the model needs perfect consistency (high temporal and spatial correlation) between the low-resolution inputs $X$ and the high-resolution target $Y$. Otherwise, the Emulator will try to learn a non-existing or non-exact relationship between $X$ and $Y$.
        \item Because of large-scale biases and inconsistencies between GCM and RCM variables, a perfect consistency cannot be guaranteed.
    \end{itemize}
    \item Creation of UPRCM: 
    \begin{itemize}
        \item To test the effect of this training framework on our Emulator, we followed the procedure outlined in~\cite{Doury} and create "GCM-like" features ($\operatorname{UPRCM}$).
        \item In a first step, we upscaled RCM features to GCM resolution ($68\times206$ km) through conservative interpolation. 
        \item In a second step, the upscaled RCM features were smoothed with a $3\times3$ moving average filter. This filter conserves the GCM grid, but each point now contains smoother information, and this further ensures the removal of local-scale information that might persist through the upscaling~\cite{Doury, Klaver2020}.
    \end{itemize}
    \item Consistency: To assess the presence of biases and inconsistencies between UPRCM and GCM features, we used two correlation statistics.  
    \begin{itemize}
        \item Temporal correlation: for each atmospheric variable $x\in C_1$ and point $p = (i,j)$ in the input domain $\mathcal{D}$, we calculated the Pearson correlation between the GCM and UPRCM time-series:
        \begin{equation}\label{eq:temporal-corr}
            \rho\left(G_{p}^x,U_{p}^x\right) = \frac{\operatorname{cov}(G_{p}^x,U_{p}^x)}{\sigma(G_{p}^x)\sigma(U_{p}^x)} \;\;\;\; \forall p \in \mathcal{D}, x\in C_1 
        \end{equation}
        where $G_{p}^x = \operatorname{GCM}[1:T, i, j, x]$, $U_{p}^x = \operatorname{UPRCM}[1:T, i, j, x]$, $\operatorname {cov}(\cdot)$  is the covariance and  $\sigma(\cdot)$ is the standard deviation.  
        \item Spatial correlation: for each $x\in C_1$ and time-step $t \in T$, we calculated the spatial correlation between GCM and UPRCM images: 
        \begin{equation}\label{eq:spatial-corr}
            \operatorname{sc}\left(G_{t}^x,U_{t}^x\right) = \frac{\operatorname{cov}(G_{t}^x,U_{t}^x)}{\sigma(G_{t}^x)\sigma(U_{t}^x)} \;\;\;\; \forall t \in T, x\in C_1 
        \end{equation}
        where $G_{t}^x = \operatorname{GCM}[t,1:I,1:J,x]$ and $U_{t}^x =\operatorname{UPRCM}[t,1:I,1:J,x]$. 
    \end{itemize}
\end{itemize}

\section{Training}\label{subsec:training}
\begin{itemize}
    \item Input to model: As aforementioned in~\ref{subsec:features}, each observation given to the Emulator are features $X_t$ and $Z_t$ for a month $t\in T$. $X_t$ is an array in $I \times J \times C_1$, where the two first dimensions are the spatial coordinates of the input domain, and the number of channels $C_1$ is the different atmospheric variables chosen as predictors. $Z_t \in C_2$ is its corresponding temporal encoding (Fig.~\ref{fig:example-features}).
    \item UPRCM and GCM: we created two Emulators by following two scenarios. We trained the first Emulator ($\operatorname{\hat{F}_U}$) following the perfect model framework (~\ref{subsec:perfect-model}) where we used upscaled RCM features as low-resolution inputs coming (UPRCM). Then, in a second step, we trained another Emulator ($\operatorname{\hat{F}_G}$) with coarse features directly from the GCM. 
    \item Why: The perfect model framework allowed us to evaluate how the U-Net performs when it has to learn only the downscaling function of the RCM. In the second training set, we wanted to see whether the model could learn the underlying dynamics, despite inconsistencies and biases, between GCM and RCM. 
    \item Loss: 
    \begin{itemize}
        \item In~\cite{Doury}, the authors propose to view the problem as regression and use Mean Squared Error (MSE) as a loss function. However, our Emulator performed poorly using an MSE loss and did not seem appropriate to our setting. 
        \item As aforementioned, the scale of SMB values vary significantly across the target domain. For example, dry inland points have minimal annual variations of SMB, with maximum values reaching under $2$ \si{mmWe/day}, while a point on the west coast can reach low extremes of $-20$ \si{mmWe/day}. In this unbalanced setting, MSE penalizes the ill-fitting of low SMB regions less than points with high values of SMB.  
        \item For this reason, we needed the points to be brought on the same scale when applying a loss function, so we chose to use a normalized RMSE (NRMSE) loss. Normalizing the RMSE facilitates comparing datasets with different scales, as in our case. 
        \item Equation: For each observation i.e., each time step $t$, given to the Emulator, we calculate the NRMSE loss between the predicted SMB value $\hat{Y}^{t}$ and the target $Y^{t}$ over all positions $p$ in the target domain $\mathcal{E}$:
        \begin{align}
        \operatorname{NRMSE}\left(Y^{t},\hat{Y}^{t}\right) &= \frac{RMSE}{Y_{\max} - Y_{\min}} \\
         &=\frac{\sqrt{\frac{1}{P}\sum_{p}(\hat{y}_{p}^{t}-y^{t}_{p})^2}}{Y_{\max} - Y_{\min}}   \;\;\;\; \forall t \in T
        \end{align}
        where $\hat{y}_{p}^{t}$ is the SMB value predicted at location $p\in \mathcal{E}$ and time $t \in T$, $P$ the number of points in $\mathcal{E}$ and $Y_{\max}$, $Y_{\min}$ are respectively the maximum and minimum value of SMB over $T$ and $\mathcal{E}$.
    \end{itemize}
    \item Other training parameters: We trained both Emulators using features from 1980-2090, an 80\%-20\% training-validation split, a batch size of 32 and over 50 epochs. We used using early stopping and a learning-rate scheduler that reduced the learning rate on loss plateaus (starting with $\operatorname{LR} = 0.005$). With this setting, Emulators $\hat{F}_U$ and $\hat{F}_G$ trained for 34 and 36 epochs before stopping. 
\end{itemize}

\section{Evaluation}\label{sec:evaluation}

% evaluation framework
\begin{figure}[!t]
  \centering
  \includegraphics[width=\columnwidth]{images/evaluation_framework.png}
  \caption []{\small Evaluation frameworks. Left: perfect world scenario where the LR input and HR truth given to the Emulator come from the RCM simulation. Right: GCM scenario where LR features come from the GCM and HR truth from the RCM. Evaluation metrics used described in~\ref{subsec:evaluation-metrics}.}
  \vspace{-3mm}
  \label{fig:evaluation-framework}
\end{figure}

\begin{itemize}
    \item Train and test set: we separate the time-frame $T$ into an approximate 90\%-10\% split with a train and test period of $T_{train} = 1980-2090$ and $T_{test} = 2090-2100$. We arbitrarily chose to put the test period at the end of the climate model's time-frame out of simplicity, but we could also have taken the test samples elsewhere as long as they are consecutive.    
    \item Evaluation of $\hat{F}_U$: Emulator $\hat{F}_U$ is first evaluated in the perfect model with UPRCM features and in a second step, on GCM inputs. 
    \item Evaluation of $\hat{F}_G$: Because we trained this Emulator on the GCM, we evaluated $\hat{F}_G$ directly on test features from the GCM. 
    \item We illustrate the two evaluation frameworks in Fig.~\ref{fig:evaluation-framework}.
    
\end{itemize}

\subsection{Evaluation metrics}\label{subsec:evaluation-metrics}
For each Emulator $\hat{F}_{(\cdot)}$ and point $p \in \mathcal{E}$, we compared the target SMB time series $Y_{p}$ to the predicted values $\widehat{Y_{p}}$ over the time period $T_{test}$. For this, we used different statistics:

\subsubsection{RMSE}\label{subsubsec:rmse}
Root Mean Squared Error (RMSE) measures the square root of the average squared differences between predicted and target observations. It is also defined as the square of the mean squared error (MSE):
\begin{align}\label{eq:RMSE}
        \operatorname{RMSE}\left(Y_{p},\widehat{Y_{p}}\right) & = \sqrt{\operatorname{MSE}\left(Y_{p},\widehat{Y_{p}}\right)} \\ & = \sqrt{\frac{1}{T}\sum_{t}(\hat{y}_{p}^{t}-y^{t}_{p})^2} & \forall p \in \mathcal{E} 
\end{align}
where $\hat{y}_{p}^{t}$ is predicted SMB value and $y^{t}_{p}$ the true SMB value at location $p\in \mathcal{E} $ and time step $t\in T$. 

\subsubsection{Pearson correlation}\label{subsubsec:pearson-corr}
The Pearson correlation coefficient measures how two continuous time series change over time as a number between -1 (negatively correlated), 0 (uncorrelated), and 1 (perfectly correlated).
\begin{align}
    \operatorname{r}\left(Y_{p},\widehat{Y_{p}}\right) = \frac{\operatorname{cov}(Y_{p},\widehat{Y_{p}})}{\sigma(Y_{p})\sigma(\widehat{Y_{p}})} \;\;\;\; \forall p \in \mathcal{E} 
\end{align}
where $\operatorname {cov}(\cdot)$  is the covariance and  $\sigma(\cdot)$ is the standard deviation.

\subsubsection{Wasserstein distance}\label{subsubsec:wasserstein}
The Wasserstein distance measures the distance between two probability density functions $f(\cdotp)$, in our case $f(Y_p)$ and $f(\widehat{Y_p})$. It is the numerical cost of an optimal transportation problem i.e., the cost of the optimal transport plan~\cite{villani} for moving the mass in the predicted
measure to match that in the target~\cite{wasserstein1}. 
\begin{equation}
    \operatorname{W}\left(f(Y_p),f(\widehat{Y_p})\right) = \sum_{t}|y^{t}_{p}-\hat{y}_{p}^{t}| \;\;\;\; \forall p \in \mathcal{E}
\end{equation}
where $\hat{y}_{p}^{t}$ is the predicted SMB value and $y^{t}_{p}$ the true SMB value at location $p\in \mathcal{E} $ and time step $t\in T$. 

\subsection{Feature importance}


\chapter{Results}
%%%%%%%%%%%%%%%%%%%%

\begin{itemize}
    \item Flow of Results section:
    \begin{itemize}
    \item Consistency: Start by evaluating consistency between GCM and UPRCM variables. Why? This way we know how much bias between LR and HR variables the Emulators are dealing with and whether a perfect model framework is necessary. Interesting to know for when UPRCM-Emulator gets GCM inputs and interesting for GCM-Emulator. 
        \item Global ML metrics: move on to evaluate models with metrics over whole target domain. Why? Start global and use typical ML metrics to evaluate performance of models.  
        \item Geoplots: Look at actual prediction images made by Emulators. Why? Good visual aid to assess which regions are best emulated. Can look at details and precision of reconstruction.   
        \item Zoom in on specific points with their time-series and annual SMB values. Why? Look at how the models adapt to different patterns and intensities of SMB. 
        \item Feature importance for both Emulators. Why? From a physical point of view, interesting to see which atmospheric variables play the biggest role in predicting SMB. 
        
    \end{itemize} 
\end{itemize}


\section{Bias between RCM and GCM variables}
To assess the bias and inconsistencies between the large-scale and fine-scale atmospheric variables, we calculated the temporal and spatial correlation between UPRCM and GCM variables (Eq.~\ref{eq:spatial-corr} and Eq.\ref{eq:temporal-corr}). 
\begin{itemize}
    \item Fig.~\ref{fig:temp-corr-GCM-UPRCM}: except for the two wind variables (NW, EW), the temporal correlation between URPCM and GCM features is high. Suggests that, except for winds, there is little inconsistencies in the seasonal patterns between regional and global variables.For the two winds, temporal patterns show inconsistencies over the mainland and Peninsula. We suspect that, due to difference in high and low pressure systems, the regional and global scale wind variables show different temporal patterns. 
    \item Fig.~\ref{fig:spatial-corr-GCM-UPRCM} and Fig.~\ref{fig:spatial-corr-GCM-RCM-ex}: variables like radiation, humidity, temperature and precipitation show significant changes in spatial correlation between UPRCM and GCM. Most flagrant variable is SWD with a highly oscillating annual pattern. Looking at individual months in Fig.~\ref{fig:spatial-corr-GCM-RCM-ex}, we see that sc is low for SWD because GCM predicts higher values of radiation inland than RCM. For precipitation, see that in the worst case, patterns in UPRCM and GCM are completely different (left). While in best case, RCM is a lot more precise in predicting precipitation patterns and overall correlation very low for this variable. Notice also boundaries of RCM model show strange streaks in patterns, but know problem for climate models.  
    \item Overall, see that problems in consistency between large scale and local scale variables. Might confuse models and might justify the use of perfect model framework to train. 
\end{itemize}


\begin{figure}[tbp]
        \centering
        \begin{subfigure}[b]{\columnwidth}
            \centering \includegraphics[width=\textwidth]{doc/Thesis-latex/images/results/temporalCorr_RCM_GCM.png}
            \caption[]%
            {{\small Temporal correlation over test period}}    
          \label{fig:temp-corr-GCM-UPRCM}
        \end{subfigure}
        \hfill
            \begin{subfigure}[b]{\columnwidth}
            \centering \includegraphics[width=\textwidth]{doc/Thesis-latex/images/results/spatialCorr_TS_RCM_GCM.png}
            \caption[]%
            {{\small Spatial correlation over test period}}    
          \label{fig:spatial-corr-GCM-UPRCM}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{\columnwidth}  
            \centering 
            \includegraphics[width=\textwidth]{doc/Thesis-latex/images/results/spatialCorr_RCM_GCM.png}
            \caption[]%
            {{\small Spatial correlation for individual variables and months}}  \label{fig:spatial-corr-GCM-RCM-ex}
        \end{subfigure}
        \hfill
        \caption[]
        {\small Temporal (a) and spatial (b, c) correlation between UPRCM and GCM variables given as input to Emulator ($\hat{F}$) over target domain ($\mathcal{E})$) and test period (2090-2100). (a) Temporal correlation between UPRCM and GCM time-series for each point $p$ in target domain $\mathcal{E}$. Legend: mean ($\mu$) and standard deviation ($\operatorname{std}$) over $\mathcal{E}$. (b) Spatial correlation between UPRCM and GCM variables over $\mathcal{E}$ for each time step. (c) Example of time steps with lowest (left) and highest (right) spatial correlation ($\operatorname{sc}$) between UPRCM and GCM. Variables from top to bottom: long-wave downward radiation (LWD), short-wave downward radiation (SWD) and precipitation (PR).} 
        \label{fig:corr-GCM-RCM}
    \end{figure}


%%%%%%%%%%%%%%%%%%%%



\section{Comparison between $\hat{F}$ on UPRCM and GCM}

\subsection{Evaluation metrics}

\begin{itemize}
    \item Close in Pearson correlation but higher difference in Wasserstein and RMSE where F(UPRCM) is closer to truth. Indicates Emulator on GCM gets idea of time series but misses amplitude.
    \item Ref Fig.~\ref{fig:evaluation-GCM-RCM}
\end{itemize}

% evaluation metrics
\begin{figure}[thb]
  \centering
  \includegraphics[width=\columnwidth]{doc/Thesis-latex/images/results/metrics_RCM_GCM.png}
  \caption []{\small Evaluation of Emulator trained on UPRCM ($\hat{F}$) or on GCM ($\hat{G}$) and using respectively UPRCM ($\operatorname{\hat{F}(UPRCM)}$) and GCM as low-resolution input ($\operatorname{\hat{F}(GCM)}$, $\operatorname{\hat{G}(GCM)}$). Test period (2090-2100). At each position $p$ in target domain $\mathcal{E}$, the truth series over the test period are compared to predicted SMB values $\operatorname{\hat{F}(\cdot)}$ and $\operatorname{\hat{G}(\cdot)}$. Right: box plot of evaluation metric values, extending from lower to upper quartile, with a line at the median and triangle at the mean. From top to bottom: Pearson correlation, Wasserstein distance and RMSE (\ref{subsubsec:rmse}). Legend: spatial mean ($\operatorname{\mu}$) and standard deviation ($\operatorname{std}$) of metric over $\mathcal{E}$. }
  \vspace{-3mm}
  \label{fig:evaluation-GCM-RCM}
\end{figure}


\subsection{Geoplots}

% SMB predictions over geoplots
\begin{figure}[thb]
  \centering
  \includegraphics[width=\columnwidth]{doc/Thesis-latex/images/results/geoplots_RCM_GCM.png}
  \caption []{\small SMB on a random month (05/1980) (top) and averaged over the test period (bottom) over $\mathcal{E}$. From left to right: SMB as in the UPRCM, true RCM, $\operatorname{\hat{F}(UPRCM)}$ and $\operatorname{\hat{F}(GCM)}$. Legend: spatial mean ($\mu$) over $\mathcal{E}$ and spatial correlation ($\operatorname{sc}$) and spatial RMSE ($\operatorname{rmse}$) between the emulated and true SMB pixel values.}
  \vspace{-3mm}
  \label{fig:geoplots-GCM-RCM}
\end{figure}

\begin{itemize}
    \item Show the predictions of the Emulator using UPRCM ($\operatorname{\hat{F}(UPRCM)}$) and with GCM ($\operatorname{\hat{F}(GCM)}$). On top you can see predictions for a random test month and on the bottom the mean values over the whole test set. 
    \item Predictions with LR images that come from an UPRCM look more similar than when the emulator gets GCM inputs. The perfect model framework captures high intensities (in red) better while predictions from GCM look like a smoothed out and toned down image.
    \item Higher spatial correlation and lower RMSE between truth and Emulator(UPRCM) and truth vs Emulator(GCM)
    \item Valid both for random month and for averaged over test period
    \item Ref Fig.~\ref{fig:geoplots-GCM-RCM}
\end{itemize}


\subsection{Time-series}
\begin{itemize}
    \item We can see difference between $\operatorname{\hat{F}(UPRCM)}$ and $\operatorname{\hat{F}(GCM)}$ even better when looking at single point time series. 
    \item We chose 4 points that behaved very differently here. Points 1 and 2 are in regions with high precipitation and so big changes in SMB, while points 3 and 4 are in dryer regions. In grey are the truth values, in blue predictions from UPRCM and in pink predictions from GCM. 
    \item Here we really see that when given GCM inputs, the emulator gets the general idea but produces a toned down version of the time series with less amplitude. Nevertheless, the predictions coming from UPRCM are very similar, hinting that the emulator is doing its downscaling job.
    \item Ref Fig.~\ref{fig:timeseries-GCM-UPRCM}
\end{itemize}

% Time series and geoplots for four points
\begin{figure}[tbp]
        \centering
        \begin{subfigure}[b]{0.2\columnwidth}
            \centering \includegraphics[width=\textwidth]{doc/Thesis-latex/images/results/points_location.png}
            \caption[]%
            {{\small}}    
          \label{fig:points-location}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{\columnwidth}  
            \centering 
           \includegraphics[width=\textwidth]{doc/Thesis-latex/images/results/timeseries_RCM_GCM.png}
            \caption[]%
            {{\small }}  
          \label{fig:timeseries-GCM-UPRCM}
        \end{subfigure}
        \hfill
        \caption[]
        {\small Predictions of Emulator trained on UPRCM ($\hat{F}$) or on GCM ($\hat{G}$) and using respectively UPRCM ($\operatorname{\hat{F}(UPRCM)}$) and GCM as low-resolution input ($\operatorname{\hat{F}(GCM)}$, $\operatorname{\hat{G}(GCM)}$). (b) Time-series of predictions of Emulator for four different geographical points (a) in target domain ($\mathcal{E})$). True SMB (grey), $\operatorname{\hat{F}(UPRCM)}$ (blue), $\operatorname{\hat{F}(GCM)}$ (green) and $\operatorname{\hat{G}(GCM)}$ (orange). Legend: temporal correlation ($\operatorname{r}$) and temporal RMSE ($\operatorname{RMSE}$) between the time-series of emulated and true SMB.. Test time-frame: 2090-2100. } 
        \label{fig:points-timeseries-GCM-UPRCM}
    \end{figure}

\subsection{Annual SMB predictions}

\begin{itemize}
    \item We also looked at the annual SMB predictions for both inputs. 
    \item Again we can see here that the model with GCM tends to underestimate the truth, while the RCM emulator comes closer to the truth in average
    \item Ref Fig.~\ref{fig:annual-SMB}
\end{itemize}





\subsection{Feature importance}


\chapter{Discussion}
%%%%%%%%%%%%%%%%%%%%

In the evaluation you convince the reader that your design works as intended.
Describe the evaluation setup, the designed experiments, and how the
experiments showcase the individual points you want to prove.

This section is usually 5-10 pages.

\begin{itemize}
    \item Model from Doury is made for super resolution with LR as input. In our case don't have LR SMB available
    \item Temporal and spatial dis-correlation between GCM and RCM. Ref: Figure~\ref{fig:corr-GCM-RCM}
    \item Model doing its job but confused by different input when given GCM while trained on UPRCM
    \item Training on GCM directly ?
\end{itemize}



%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusion}
%%%%%%%%%%%%%%%%%%%%

In the conclusion you repeat the main result and finalize the discussion of
your project. Mention the core results and why as well as how your system
advances the status quo.

\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{Bibliography}
\printbibliography

% Appendices are optional
\appendix
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Data processing}
\begin{figure}[!t]
  \centering
  \includegraphics[width=\columnwidth]{images/data-flow.png}
  \caption []{\small Training data flow}
  \vspace{-3\si{mmWe/day}\sci{km}}
  \label{fig:training-data-flow}
\end{figure}
\section{Pre-processing of RCM}
\begin{itemize}
    \item  Because GCM data we have is monthly frequency, do monthly mean aggregation for RCM data.

\end{itemize}
\section{Pre-processing of GCM}
\chapter{Feature selection}
\section{Feature selection RCM}
\section{Feature selection GCM}

\chapter{Hyperparameter tuning}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\include{table1}
% In case you ever need an (optional) appendix.
%
% You need the following items:
% \begin{itemize}
% \item A box
% \item Crayons
% \item A self-aware 5-year old
% \end{itemize}

\end{document}